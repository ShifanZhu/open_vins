/**


@page update-feat Feature Bearing Update
@tableofcontents

@section model General Measurement Equation


Consider a 3D feature that has been tracked over a window of poses in a camera.
At each timestep we have a uv measurement of this feature on the image plane.
We can define the following measurement:

\f{align*}{
    \mathbf{z}_m &= \mathbf{z}_k + \mathbf{n}_k
\f}

where \f$\mathbf{z}_m\f$ is a single uv measurement on the image plane from a given camera that has some pixel noise  \f$\mathbf{n}_k\f$.
We now can write how this is a function of the state as follows:


\f{align*}{
    \mathbf{z}_m
    &=w(\mathbf{z}'_k, ~\boldsymbol\zeta) + \mathbf{n}_k \\
    &=w(\pi({}^{C_k}\mathbf{p}_f), ~\boldsymbol\zeta) + \mathbf{n}_k \\
    &=w(\pi(r({}^{G}\mathbf{p}_f,~{}^{C_k}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_k})), ~\boldsymbol\zeta) + \mathbf{n}_k \\
    &=w(\pi(r(f(\boldsymbol\lambda,\cdots),~{}^{C_k}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_k})), ~\boldsymbol\zeta) + \mathbf{n}_k
\f}


Each of these functions correspond to different operations that convert our state representation into the final raw uv measurement on the image plane.
Since we eventually want to perform intrinsic calibration along with extrinsic with different representations, the above function is very general.
The high level description of each function is as follows:


| Function | Description |
|---|---|
| \f$\mathbf{z}_k = w(\mathbf{z}'_k, ~\boldsymbol\zeta)\f$ | The undistort function that takes normalized coordinates and maps it into raw distorted uv coordinates |
|\f$\mathbf{z}'_k=\pi({}^{C_k}\mathbf{p}_f)\f$| The projection function that takes a 3D point in the image and converts it into the normalized uv coordinates |
|\f${}^{C_k}\mathbf{p}_f=r({}^{G}\mathbf{p}_f,~{}^{C_k}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_k})\f$ | Maps a feature in the global frame into the current camera frame |
| \f${}^{G}\mathbf{p}_f=f(\boldsymbol\lambda,\cdots)\f$ | Converts from a feature representation to a 3D feature in the global frame |




@section distortion Distortion Function

@subsection distortion-radtan Radial Distortion

To calibrate our intrinsics we need to know how to map our normalized coordinates into the raw pixel coordinates on the image plane.
We need to first undistort our normalized coordinates and then project it onto the unit image plane using our focal length and camera center.
Looking at the [OpenCV model](https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#details) for radial distortion we have the following equation:
\f{align*}{
    \mathbf{z}_k &= w(\mathbf{z}'_k, ~\boldsymbol\zeta) \\[1em]
\empty
    x' &= x (1 + k_1 r^2 + k_2 r^4) + 2 p_1 x y + p_2(r^2 + 2 x^2) \\\
    y' &= y (1 + k_1 r^2 + k_2 r^4) + p_1 (r^2 + 2 y^2) + 2 p_2 x y \\[1em]
\empty    
    \text{where} &\quad r^2 = x^2 + y^2 \\
    &\quad \begin{bmatrix} x \\ y \end{bmatrix} = \mathbf{z}'_k \\[1em]
    u &= f_x*x' + c_x \\
    v &= f_y*y' + c_y
\f}


where x and y are the normalized coordinates of the 3D feature and u and v are the distorted image coordinates on the image plane.
We consider the case where we are estimating at maximum the following distortion and camera intrinsics parameters (note that we do not estimate the higher order terms since most offline calibration such as [Kalibr](https://github.com/ethz-asl/kalibr) only report the first four):
\f{align*}{
\boldsymbol\zeta = \begin{bmatrix} f_x & f_y & c_x & c_y & k_1 & k_2 & p_1 & p_2 \end{bmatrix}
\f}


We have the following Jacobian for these elements:
\f{align*}{
\frac{\partial w(\cdot)}{\partial \boldsymbol\zeta} = 
\begin{bmatrix}
x' & 0  & 1 & 0 & f_x*(xr^2) & f_x*(xr^4) & f_x*(2xy) & f_x*(r^2+2x^2)  \\[5pt]
0  & y' & 0 & 1 & f_y*(yr^2) & f_y*(yr^4) & f_y*(r^2+2y^2) & f_y*(2xy)
\end{bmatrix}
\f}


We have the Jacobian in respect to the normalized coordinates as follows:
\f{align*}{
\frac{\partial w(\cdot)}{\partial \mathbf{z}'_k} = 
\begin{bmatrix}
f_x*((1+k_1r^2+k_2r^4)+(2k_1x^2+4k_2x^2(x^2+y^2))+2p_1y+(2p_2x+4p_2x))  &  f_x*(2k_1xy+4k_2xy(x^2+y^2)+2p_1x+2p_2y)    \\
f_y*(2k_1xy+4k_2xy(x^2+y^2)+2p_1x+2p_2y)  &  f_y*((1+k_1r^2+k_2r^4)+(2k_1y^2+4k_2y^2(x^2+y^2))+(2p_1y+4p_1y)+2p_2x)
\end{bmatrix}
\f}






@subsection distortion-equi Fisheye Distortion


The second model is that of the [OpenCV fisheye](https://docs.opencv.org/3.4/db/d58/group__calib3d__fisheye.html#details) model which allows us to handel larger FOV lenses.
Given the 3D point in normalized image coordinates, we can first distort it and then project it onto the unit image plane using our focal length and camera center.
We have the following model:
\f{align*}{
    \mathbf{z}_k &= w(\mathbf{z}'_k, ~\boldsymbol\zeta) \\[1em]
\empty
    \theta_d &= \theta (1 + k_1 \theta^2 + k_2 \theta^4 + k_3 \theta^6 + k_4 \theta^8) \\
    x' &= \frac{x}{r} * \theta_d \\
    y' &= \frac{y}{r} * \theta_d \\[1em]
\empty
    \text{where} &\quad r^2 = x^2 + y^2 \\
    &\quad \theta = atan(r) \\
    &\quad\begin{bmatrix} x \\ y \end{bmatrix} = \mathbf{z}'_k \\[1em]
\empty
    u &= f_x * x' + c_x \\
    v &= f_y * y' + c_y
\f}


where x and y are the normalized coordinates of the 3D feature and u and v are the distorted image coordinates on the image plane.
We consider the case where we are estimating at maximum the following distortion and camera intrinsics parameters (note that we do not estimate the skew term since most offline calibration such as [Kalibr](https://github.com/ethz-asl/kalibr) only report the first four):
\f{align*}{
\boldsymbol\zeta = \begin{bmatrix} f_x & f_y & c_x & c_y & k_1 & k_2 & k_3 & k_4 \end{bmatrix}
\f}


We have the following Jacobian for these elements:
\f{align*}{
\frac{\partial w(\cdot)}{\partial \boldsymbol\zeta} = 
\begin{bmatrix}
x' & 0  & 1 & 0 & f_x*(\frac{x}{r}\theta^3) & f_x*(\frac{x}{r}\theta^5) & f_x*(\frac{x}{r}\theta^7) & f_x*(\frac{x}{r}\theta^9)  \\[5pt]
0  & y' & 0 & 1 & f_y*(\frac{y}{r}\theta^3) & f_y*(\frac{y}{r}\theta^5) & f_y*(\frac{y}{r}\theta^7) & f_y*(\frac{y}{r}\theta^9)
\end{bmatrix}
\f}


We have the compound Jacobian in respect to the normalized coordinates as follows:
\f{align*}{
    \frac{\partial w(\cdot)}{\partial \mathbf{z}'_k} &= 
    \frac{\partial uv}{\partial xy'}\frac{\partial xy'}{\partial xy}+
    \frac{\partial uv}{\partial xy'}\frac{\partial xy'}{\partial r}\frac{\partial r}{\partial xy}+
    \frac{\partial uv}{\partial xy'}\frac{\partial xy'}{\partial \theta_d}\frac{\partial \theta_d}{\partial \theta}\frac{\partial \theta}{\partial r}\frac{\partial r}{\partial xy} \\[1em]
\empty
    \frac{\partial uv}{\partial xy'} &= \begin{bmatrix} f_x & 0 \\ 0 & f_y \end{bmatrix} \\
\empty
    \frac{\partial xy'}{\partial xy} &= \begin{bmatrix} \theta_d/r & 0 \\ 0 & \theta_d/r \end{bmatrix} \\
\empty
    \frac{\partial xy'}{\partial r} &= \begin{bmatrix} -\frac{x}{r^2}\theta_d \\ -\frac{y}{r^2}\theta_d \end{bmatrix} \\
\empty
    \frac{\partial r}{\partial xy} &= \begin{bmatrix} \frac{x}{r} & \frac{y}{r} \end{bmatrix} \\
\empty
    \frac{\partial xy'}{\partial \theta_d} &= \begin{bmatrix} \frac{x}{r} \\ \frac{y}{r} \end{bmatrix} \\
\empty
    \frac{\partial \theta_d}{\partial \theta} &= \begin{bmatrix} 1 + 3k_1 \theta^2 + 5k_2 \theta^4 + 7k_3 \theta^6 + 9k_4 \theta^8\end{bmatrix} \\
\empty
    \frac{\partial \theta}{\partial r} &= \begin{bmatrix} \frac{1}{r^2+1} \end{bmatrix}
\f}






@section projection Projection Function


This function takes a 3D point in the *camera* frame and converts it into normalized image coordinates.
We can take the derivative in respect to the original 3D feature to get the following:

 
\f{align*}{
    \mathbf{z}'_k &= \pi({}^{C_k}\mathbf{p}_f) \\[1em]
\empty
    \mathbf{z}'_k &=
    \begin{bmatrix}
    {}^Cx/{}^Cz \\
    {}^Cy/{}^Cz
    \end{bmatrix} \\[1em]
\empty
    \text{where} &\quad \begin{bmatrix} {}^Cx \\ {}^Cy \\ {}^Cz \end{bmatrix}  = {}^{C_k}\mathbf{p}_f
\f}



\f{align*}{
\frac{\partial \pi(\cdot)}{\partial {}^{C_k}\mathbf{p}_f} = 
\begin{bmatrix}
1/{}^Cz & 0 & -{}^Cx/({}^Cz)^2 \\
0 & 1/{}^Cz & -{}^Cy/({}^Cz)^2 \\
\end{bmatrix}
\f}




@section relative Relative Transform

Given a feature in the global frame, this function maps it into the current camera frame.
This is a function of the feature in the global, along with the transform to the current camera frame.
We have the following transformation:


\f{align*}{
    {}^{C_k}\mathbf{p}_f
    &=r({}^{G}\mathbf{p}_f,~{}^{C_k}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_k}) \\
    &=
    {}^{C}_{I}\mathbf{R}{}^{I_k}_{G}\mathbf{R}({}^{G}\mathbf{p}_f-{}^{G}\mathbf{p}_{I_k})
    +{}^{C}\mathbf{p}_I
\f}

We can take the derivative in respect to the feature in the global frame:
\f{align*}{
\frac{\partial r(\cdot)}{\partial {}^{G}\mathbf{p}_f} &= {}^{C}_{I}\mathbf{R}{}^{I_k}_{G}\mathbf{R}
\f}



We can take the derivative in respect to the IMU state \f${I_k}\f$ as follows:
\f{align*}{
\frac{\partial r(\cdot)}{\partial {}^{I_k}_{G}\mathbf{R}} &= {}^{C}_{I}\mathbf{R} \left\lfloor {}^{I_k}_{G}\mathbf{R}({}^{G}\mathbf{p}_f-{}^{G}\mathbf{p}_{I_k}) \times\right\rfloor \\
\frac{\partial r(\cdot)}{\partial {}^{G}\mathbf{p}_{I_k}} &= -{}^{C}_{I}\mathbf{R}{}^{I_k}_{G}\mathbf{R}
\f}


If we are doing online calibration, we can take the derivatives in respect to the IMU to CAM transformation also:
\f{align*}{
\frac{\partial r(\cdot)}{\partial {}^{C}_{I}\mathbf{R}} &= \left\lfloor {}^{C}_{I}\mathbf{R}{}^{I_k}_{G}\mathbf{R}({}^{G}\mathbf{p}_f-{}^{G}\mathbf{p}_{I_k}) \times\right\rfloor  \\
\frac{\partial r(\cdot)}{\partial {}^{C}\mathbf{p}_I} &= \mathbf{I}_{3\times 3}
\f}









@section feat-rep Feature Representation

To allow for multiple different types of feature representations, we define an arbitrary function that itself can be a function of the state and the chosen feature representation.
The two representations that we leverage here are a 3D point and bearing with inverse depth.
Both of these can either be represented in the global frame or in an anchor frame of reference which adds a dependency on having an "anchor" pose the feature is seen in.

@subsection feat-rep-global-xyz Global XYZ

For the global representation we have the following:

\f{align*}{
{}^{G}\mathbf{p}_f
&= f(\boldsymbol\lambda) \\
&= \begin{bmatrix} {}^Gx \\ {}^Gy \\ {}^Gz \end{bmatrix} \\
\text{where} &\quad \boldsymbol\lambda = {}^{G}\mathbf{p}_f = \begin{bmatrix} {}^Gx & {}^Gy & {}^Gz \end{bmatrix}^\top
\f}

It is clear that the Jacobian  in respect to the feature state is just the following:
\f{align*}{
\frac{\partial f(\cdot)}{\partial \boldsymbol\lambda} &= \mathbf{I}_{3\times 3}
\f}



@subsection feat-rep-global-inv Global Inverse Depth

For the global inverse representation we have the following:

\f{align*}{
{}^{G}\mathbf{p}_f
&= f(\boldsymbol\lambda) \\
&= \frac{1}{\rho}\begin{bmatrix} \cos(\theta)\sin(\phi) \\ \sin(\theta)\sin(\phi) \\ \cos(\phi) \end{bmatrix} \\
\text{where} &\quad \boldsymbol\lambda = \begin{bmatrix} \theta & \phi & \rho \end{bmatrix}^\top
\f}

The Jacobian  in respect to the feature state is just the following:
\f{align*}{
\frac{\partial f(\cdot)}{\partial \boldsymbol\lambda} &= 
\begin{bmatrix}
-\frac{1}{\rho}\sin(\theta)\sin(\phi) & \frac{1}{\rho}\cos(\theta)\cos(\phi) & -\frac{1}{\rho^2}\cos(\theta)\sin(\phi) \\
\frac{1}{\rho}\cos(\theta)\sin(\phi) & \frac{1}{\rho}\sin(\theta)\cos(\phi) & -\frac{1}{\rho^2}\sin(\theta)\sin(\phi) \\
0 & -\frac{1}{\rho}\sin(\phi) & -\frac{1}{\rho^2}\cos(\phi)
\end{bmatrix}
\f}


@subsection feat-rep-global-inv2 Global Inverse Depth (MSCKF VERSION)

This representation has a singularity when the vertical z-distance goes to zero.
Thus one should never represent this in a global frame, and instead should use the @ref feat-rep-anchor-inv2 representation.
The anchored version doesn't have this issue if you represent the feature in a camera frame that it was seen from (which a feature should never have a non-positive z-direction).




@subsection feat-rep-anchor-xyz Anchored XYZ

To "anchor" a feature, we say that it has been seen from some anchor pose which is in the camera sensor frame of reference.
This would normally be the first pose that an observation of the feature was seen from.
Thus, our feature measurement is a function of this anchor state as follows:

\f{align*}{
{}^{G}\mathbf{p}_f
&= f(\boldsymbol\lambda,~{}^{C_a}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_a}) \\
&=
{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) + {}^{G}\mathbf{p}_{I_a} \\
\text{where} &\quad \boldsymbol\lambda = {}^{C_a}\mathbf{p}_f = \begin{bmatrix} {}^{C_a}x & {}^{C_a}y & {}^{C_a}z \end{bmatrix}^\top
\f}

It is clear that the Jacobian in respect to the feature state is just the following:
\f{align*}{
\frac{\partial f(\cdot)}{\partial \boldsymbol\lambda} &= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top
\f}


We additionally have the following Jacobians in respect to the anchor state:
\f{align*}{
    \frac{\partial f(\cdot)}{\partial {}^{I_a}_{G}\mathbf{R}} &= -{}^{I_a}_{G}\mathbf{R}^\top \left\lfloor{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\
    \frac{\partial f(\cdot)}{\partial {}^{G}\mathbf{p}_{I_a}} &= \mathbf{I}_{3\times 3}
\f}


If we are doing extrinsic calibration we also have the following Jacobians for the IMU to CAM transform:
\f{align*}{
    \frac{\partial f(\cdot)}{\partial {}^{C}_{I}\mathbf{R}} &= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \left\lfloor({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\
    \frac{\partial f(\cdot)}{\partial {}^{C}\mathbf{p}_{I}} &= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top
\f}




@subsection feat-rep-anchor-inv Anchored Inverse Depth

To "anchor" a feature, we say that it has been seen from some anchor pose which is in the camera sensor frame of reference.
This would normally be the first pose that an observation of the feature was seen from.
Thus, our feature measurement is a function of this anchor state as follows:

\f{align*}{
{}^{G}\mathbf{p}_f
&= f(\boldsymbol\lambda,~{}^{C_a}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_a}) \\
&=
{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) + {}^{G}\mathbf{p}_{I_a} \\
&=
{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top\Bigg(\frac{1}{\rho}\begin{bmatrix} \cos(\theta)\sin(\phi) \\ \sin(\theta)\sin(\phi) \\ \cos(\phi) \end{bmatrix}-{}^{C}\mathbf{p}_{I}\Bigg) + {}^{G}\mathbf{p}_{I_a} \\
\text{where} &\quad \boldsymbol\lambda = \begin{bmatrix} \theta & \phi & \rho \end{bmatrix}^\top
\f}

The Jacobian in respect to the feature state is exactly the same as the global representation with additional rotation matrices:
\f{align*}{
\frac{\partial f(\cdot)}{\partial \boldsymbol\lambda} &= 
{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top
\begin{bmatrix}
-\frac{1}{\rho}\sin(\theta)\sin(\phi) & \frac{1}{\rho}\cos(\theta)\cos(\phi) & -\frac{1}{\rho^2}\cos(\theta)\sin(\phi) \\
\frac{1}{\rho}\cos(\theta)\sin(\phi) & \frac{1}{\rho}\sin(\theta)\cos(\phi) & -\frac{1}{\rho^2}\sin(\theta)\sin(\phi) \\
0 & -\frac{1}{\rho}\sin(\phi) & -\frac{1}{\rho^2}\cos(\phi)
\end{bmatrix}
\f}


We additionally have the following Jacobians in respect to the anchor state:
\f{align*}{
    \frac{\partial f(\cdot)}{\partial {}^{I_a}_{G}\mathbf{R}} &= -{}^{I_a}_{G}\mathbf{R}^\top \left\lfloor{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\
    \frac{\partial f(\cdot)}{\partial {}^{G}\mathbf{p}_{I_a}} &= \mathbf{I}_{3\times 3}
\f}


If we are doing extrinsic calibration we also have the following Jacobians for the IMU to CAM transform:
\f{align*}{
    \frac{\partial f(\cdot)}{\partial {}^{C}_{I}\mathbf{R}} &= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \left\lfloor({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\
    \frac{\partial f(\cdot)}{\partial {}^{C}\mathbf{p}_{I}} &= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top
\f}






@subsection feat-rep-anchor-inv2 Anchored Inverse Depth (MSCKF VERSION)

We may also define a simpler version of inverse depth, as is presented in the original MSCKF paper. The 3D position of the feature is then given by:

\f{align*}{
{}^{G}\mathbf{p}_f
&= f(\boldsymbol\lambda,~{}^{C_a}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_a}) \\
&=
{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) + {}^{G}\mathbf{p}_{I_a} \\
&=
{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top\Bigg(\frac{1}{\rho}\begin{bmatrix} \alpha \\ \beta \\ 1 \end{bmatrix}-{}^{C}\mathbf{p}_{I}\Bigg) + {}^{G}\mathbf{p}_{I_a} \\
\text{where} &\quad \boldsymbol\lambda = \begin{bmatrix} \alpha & \beta & \rho \end{bmatrix}^\top
\f}

The Jacobian in respect to the feature state is then:
\f{align*}{
\frac{\partial f(\cdot)}{\partial \boldsymbol\lambda} &= 
{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top
\begin{bmatrix}
\frac{1}{\rho} & 0 & -\frac{1}{\rho^2}\alpha \\
0 & \frac{1}{\rho} & -\frac{1}{\rho^2}\beta \\
0 & 0 & -\frac{1}{\rho^2}
\end{bmatrix}
\f}


We additionally have the following Jacobians in respect to the anchor state:
\f{align*}{
    \frac{\partial f(\cdot)}{\partial {}^{I_a}_{G}\mathbf{R}} &= -{}^{I_a}_{G}\mathbf{R}^\top \left\lfloor{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\
    \frac{\partial f(\cdot)}{\partial {}^{G}\mathbf{p}_{I_a}} &= \mathbf{I}_{3\times 3}
\f}


If we are doing extrinsic calibration we also have the following Jacobians for the IMU to CAM transform:
\f{align*}{
    \frac{\partial f(\cdot)}{\partial {}^{C}_{I}\mathbf{R}} &= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \left\lfloor({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\
    \frac{\partial f(\cdot)}{\partial {}^{C}\mathbf{p}_{I}} &= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top
\f}




*/
